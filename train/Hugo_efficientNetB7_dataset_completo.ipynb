{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 16 23:41:29 2025       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    35W / 300W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 23.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.4\n",
      "    Uninstalling pip-20.2.4:\n",
      "      Successfully uninstalled pip-20.2.4\n",
      "Successfully installed pip-21.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 9.4 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: dataclasses, torch\n",
      "Successfully installed dataclasses-0.8 torch-1.10.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 16 23:42:26 2025       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    36W / 300W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 1.3 MB/s             \n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm) (3.4.0)\n",
      "Installing collected packages: importlib-resources, tqdm\n",
      "Successfully installed importlib-resources-5.4.0 tqdm-4.64.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp36-cp36m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |████████████████████████████████| 23.3 MB 23.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.19.5)\n",
      "Collecting torch==1.10.1\n",
      "  Downloading torch-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 5.9 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (8.1.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.10.1->torchvision) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.2\n",
      "    Uninstalling torch-1.10.2:\n",
      "      Successfully uninstalled torch-1.10.2\n",
      "Successfully installed torch-1.10.1 torchvision-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.15.2 (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.3.0, 0.4.0, 0.4.0+cpu, 0.4.0+cu92, 0.4.1, 0.4.1+cpu, 0.4.1+cu100, 0.4.1+cu92, 0.4.2, 0.4.2+cpu, 0.4.2+cu100, 0.4.2+cu92, 0.5.0, 0.5.0+cpu, 0.5.0+cu100, 0.5.0+cu92, 0.6.0, 0.6.0+cpu, 0.6.0+cu101, 0.6.0+cu92, 0.6.1, 0.6.1+cpu, 0.6.1+cu101, 0.6.1+cu92, 0.7.0, 0.7.0+cpu, 0.7.0+cu101, 0.7.0+cu92, 0.8.0, 0.8.1, 0.8.1+cpu, 0.8.1+cu101, 0.8.1+cu110, 0.8.1+cu92, 0.8.2, 0.8.2+cpu, 0.8.2+cu101, 0.8.2+cu110, 0.8.2+cu92, 0.9.0, 0.9.0+cpu, 0.9.0+cu101, 0.9.0+cu111, 0.9.1, 0.9.1+cpu, 0.9.1+cu101, 0.9.1+cu102, 0.9.1+cu111, 0.10.0, 0.10.0+cpu, 0.10.0+cu102, 0.10.0+cu111, 0.10.0+rocm4.1, 0.10.0+rocm4.2, 0.10.1, 0.10.1+cpu, 0.10.1+cu102, 0.10.1+cu111, 0.10.1+rocm4.1, 0.10.1+rocm4.2, 0.11.0, 0.11.0+cpu, 0.11.0+cu102, 0.11.0+cu111, 0.11.0+cu113, 0.11.0+rocm4.1, 0.11.0+rocm4.2, 0.11.1, 0.11.1+cpu, 0.11.1+cu102, 0.11.1+cu111, 0.11.1+cu113, 0.11.1+rocm4.1, 0.11.1+rocm4.2, 0.11.2, 0.11.2+cpu, 0.11.2+cu102, 0.11.2+cu111, 0.11.2+cu113, 0.11.2+rocm4.1, 0.11.2+rocm4.2, 0.11.3+cpu, 0.11.3+cu102, 0.11.3+cu111, 0.11.3+cu113, 0.11.3+rocm4.1, 0.11.3+rocm4.2)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for torchvision==0.15.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.15.2 torch==1.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.2+cu102\n"
     ]
    }
   ],
   "source": [
    "import torchvision; \n",
    "print(torchvision.__version__)\n",
    "\n",
    "# from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 16 23:43:25 2025       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    36W / 300W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.1.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv-python-4.11.0.86.tar.gz (95.2 MB)\n",
      "     |████████████████████████████████| 95.2 MB 16 kB/s              \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n",
      "Building wheels for collected packages: opencv-python\n",
      "  Building wheel for opencv-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opencv-python: filename=opencv_python-4.11.0.86-cp36-cp36m-linux_x86_64.whl size=29806470 sha256=f1632fe0301879e3875f5a0b5058440ba98e1e6fd3d02d8c9edd00eeed55bd68\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/2a/d7/251a9209220b85f8ea16b78b62a04f53c9ee09f612d24df6fc\n",
      "Successfully built opencv-python\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "     |████████████████████████████████| 22.2 MB 27.0 MB/s            \n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "     |████████████████████████████████| 25.9 MB 27.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "     |████████████████████████████████| 309 kB 27.5 MB/s            \n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.1 scikit-learn-0.24.2 scipy-1.5.4 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory before start: 1.00 GB allocated\n",
      "GPU memory reserved: 2.46 GB reserved\n",
      "Training started at: 2025-06-07 13:34:52\n",
      "Classes detectadas: ['DeepFakeDetection', 'FaceShifter', 'FaceSwap', 'NeuraTextures', 'deepfakes', 'face2face', 'original']\n",
      "Dataset sizes - Train: 3058, Val: 434, Test: 874\n",
      "Using device: cuda\n",
      "GPU memory before model loading: 1.00 GB allocated\n",
      "GPU memory available: 14.90 GB\n",
      "Loading EfficientNet-B7 + LSTM + DCT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after moving to GPU: 1.27 GB allocated\n",
      "GPU memory reserved: 2.46 GB reserved\n",
      "Model loaded. Total parameters: 67,726,591\n",
      "Starting with batch size 4, sequence length 8\n",
      "\n",
      "==================================================\n",
      "STARTING TRAINING\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: nan | Train Acc: 14.69% | Val Loss: nan | Val Acc: 14.29% | Time: 843.59s | LR: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a142f754adf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mtrain_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{epochs} - Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a142f754adf0>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Apply transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1196\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrightness_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontrast_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msaturation_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36madjust_contrast\u001b[0;34m(img, contrast_factor)\u001b[0m\n\u001b[1;32m    806\u001b[0m     \"\"\"\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36madjust_contrast\u001b[0;34m(img, contrast_factor)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0menhancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageEnhance.py\u001b[0m in \u001b[0;36menhance\u001b[0;34m(self, factor)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegenerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mblend\u001b[0;34m(im1, im2, alpha)\u001b[0m\n\u001b[1;32m   3000\u001b[0m     \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3001\u001b[0m     \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3002\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import efficientnet_b7\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.95)\n",
    "    print(f\"GPU memory before start: {torch.cuda.memory_allocated()/1024**3:.2f} GB allocated\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB reserved\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# DCT feature extraction function\n",
    "def extract_dct_features(image, num_coeffs=64):\n",
    "    \"\"\"Extract DCT features from an image\"\"\"\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # Convert to grayscale if RGB\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # Apply DCT\n",
    "    dct_coeffs = cv2.dct(np.float32(gray))\n",
    "    \n",
    "    # Extract top-left coefficients in zigzag order\n",
    "    h, w = dct_coeffs.shape\n",
    "    coeffs = []\n",
    "    \n",
    "    # Simple zigzag extraction (first 64 coefficients)\n",
    "    for i in range(min(8, h)):\n",
    "        for j in range(min(8, w)):\n",
    "            if len(coeffs) < num_coeffs:\n",
    "                coeffs.append(dct_coeffs[i, j])\n",
    "    \n",
    "    # Pad if necessary\n",
    "    while len(coeffs) < num_coeffs:\n",
    "        coeffs.append(0.0)\n",
    "    \n",
    "    return np.array(coeffs[:num_coeffs], dtype=np.float32)\n",
    "\n",
    "# Custom Dataset for sequence processing\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, sequence_length=8):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Get all image paths and their labels\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        \n",
    "        classes = sorted(os.listdir(root_dir))\n",
    "        for idx, class_name in enumerate(classes):\n",
    "            self.class_to_idx[class_name] = idx\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                images = sorted([f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                \n",
    "                # Group images into sequences\n",
    "                for i in range(0, len(images) - sequence_length + 1, sequence_length):\n",
    "                    sequence_paths = [os.path.join(class_dir, images[j]) for j in range(i, i + sequence_length)]\n",
    "                    self.samples.append((sequence_paths, idx))\n",
    "        \n",
    "        self.classes = classes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence_paths, label = self.samples[idx]\n",
    "        \n",
    "        sequence = []\n",
    "        dct_features = []\n",
    "        \n",
    "        for img_path in sequence_paths:\n",
    "            # Load image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Extract DCT features before transform\n",
    "            dct_feat = extract_dct_features(np.array(image))\n",
    "            dct_features.append(dct_feat)\n",
    "            \n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            sequence.append(image)\n",
    "        \n",
    "        # Stack sequence: [T, C, H, W]\n",
    "        sequence = torch.stack(sequence)\n",
    "        \n",
    "        # Average DCT features across sequence\n",
    "        dct_features = np.mean(dct_features, axis=0)\n",
    "        dct_features = torch.tensor(dct_features, dtype=torch.float32)\n",
    "        \n",
    "        return sequence, dct_features, label\n",
    "\n",
    "# EfficientNet-B7 + LSTM + DCT Model\n",
    "class EfficientNetLSTMDCT(nn.Module):\n",
    "    def __init__(self, num_classes, lstm_hidden_size=128, dct_size=64, sequence_length=8):\n",
    "        super(EfficientNetLSTMDCT, self).__init__()\n",
    "        \n",
    "        # EfficientNet-B7 backbone\n",
    "        self.efficientnet = efficientnet_b7(weights='DEFAULT')\n",
    "        \n",
    "        # Remove the final classifier to get features\n",
    "        self.feature_extractor = nn.Sequential(*list(self.efficientnet.children())[:-1])\n",
    "        \n",
    "        # Get feature size from EfficientNet-B7\n",
    "        self.feature_size = 2560  # EfficientNet-B7 feature size\n",
    "        \n",
    "        # LSTM for temporal modeling\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.feature_size,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Final classifier (LSTM output + DCT features)\n",
    "        self.classifier = nn.Linear(lstm_hidden_size + dct_size, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, dct_features):\n",
    "        # x shape: [B, T, C, H, W]\n",
    "        batch_size, sequence_length, channels, height, width = x.shape\n",
    "        \n",
    "        # Reshape to process all frames at once: [B*T, C, H, W]\n",
    "        x = x.view(batch_size * sequence_length, channels, height, width)\n",
    "        \n",
    "        # Extract features from all frames\n",
    "        with torch.cuda.amp.autocast():\n",
    "            features = self.feature_extractor(x)  # [B*T, 2560, 1, 1]\n",
    "        \n",
    "        # Global average pooling and flatten\n",
    "        features = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
    "        features = features.view(batch_size * sequence_length, -1)  # [B*T, 2560]\n",
    "        \n",
    "        # Reshape back to sequences: [B, T, 2560]\n",
    "        features = features.view(batch_size, sequence_length, -1)\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, (hidden, cell) = self.lstm(features)\n",
    "        \n",
    "        # Use the last hidden state\n",
    "        sequence_features = hidden[-1]  # [B, lstm_hidden_size]\n",
    "        \n",
    "        # Concatenate with DCT features\n",
    "        combined_features = torch.cat([sequence_features, dct_features], dim=1)\n",
    "        \n",
    "        # Apply dropout and final classification\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        output = self.classifier(combined_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "base_dir = \"face_extraction/faceforensis_face_extract\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir   = os.path.join(base_dir, \"val\")\n",
    "test_dir  = os.path.join(base_dir, \"test\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "SEQUENCE_LENGTH = 8\n",
    "train_dataset = SequenceDataset(root_dir=train_dir, transform=transform_train, sequence_length=SEQUENCE_LENGTH)\n",
    "val_dataset   = SequenceDataset(root_dir=val_dir, transform=transform_val_test, sequence_length=SEQUENCE_LENGTH)\n",
    "test_dataset  = SequenceDataset(root_dir=test_dir, transform=transform_val_test, sequence_length=SEQUENCE_LENGTH)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"Classes detectadas:\", class_names)\n",
    "\n",
    "BATCH_SIZE = 4  # Reduced due to sequence processing and memory requirements\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU memory before model loading: {torch.cuda.memory_allocated()/1024**3:.2f} GB allocated\")\n",
    "    print(f\"GPU memory available: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated())/1024**3:.2f} GB\")\n",
    "\n",
    "print(\"Loading EfficientNet-B7 + LSTM + DCT model...\")\n",
    "model = EfficientNetLSTMDCT(num_classes=len(class_names), lstm_hidden_size=128, dct_size=64, sequence_length=SEQUENCE_LENGTH)\n",
    "model = model.to(device)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU memory after moving to GPU: {torch.cuda.memory_allocated()/1024**3:.2f} GB allocated\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB reserved\")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler() if device == \"cuda\" else None\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "print(f\"Model loaded. Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Starting with batch size {BATCH_SIZE}, sequence length {SEQUENCE_LENGTH}\")\n",
    "\n",
    "epochs = 20\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\", leave=False)\n",
    "    for batch_idx, (sequences, dct_features, labels) in enumerate(train_bar):\n",
    "        try:\n",
    "            sequences = sequences.to(device, non_blocking=True)\n",
    "            dct_features = dct_features.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    preds = model(sequences, dct_features)\n",
    "                    loss = criterion(preds, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                preds = model(sequences, dct_features)\n",
    "                loss = criterion(preds, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(preds, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            current_acc = 100.0 * train_correct / train_total\n",
    "            train_bar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\", \n",
    "                \"acc\": f\"{current_acc:.2f}%\",\n",
    "                \"mem\": f\"{torch.cuda.memory_allocated()/1024**3:.1f}GB\"\n",
    "            })\n",
    "            \n",
    "            if batch_idx % 2 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                print(f\"\\nOUT OF MEMORY at batch {batch_idx}!\")\n",
    "                print(f\"GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB allocated\")\n",
    "                print(\"Try reducing batch size or sequence length\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                raise e\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100.0 * train_correct / train_total\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for sequences, dct_features, labels in val_bar:\n",
    "            sequences = sequences.to(device, non_blocking=True)\n",
    "            dct_features = dct_features.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    preds = model(sequences, dct_features)\n",
    "                    val_loss = criterion(preds, labels)\n",
    "            else:\n",
    "                preds = model(sequences, dct_features)\n",
    "                val_loss = criterion(preds, labels)\n",
    "            \n",
    "            val_running_loss += val_loss.item()\n",
    "            _, predicted = torch.max(preds, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            \n",
    "            current_val_acc = 100.0 * val_correct / val_total\n",
    "            val_bar.set_postfix({\"acc\": f\"{current_val_acc:.2f}%\"})\n",
    "\n",
    "    val_acc = 100.0 * val_correct / val_total\n",
    "    val_loss_avg = val_running_loss / len(val_loader)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model_EfficientNet-B7-LSTM-DCT.pth\")\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss_avg:.4f} | Val Acc: {val_acc:.2f}% | \"\n",
    "          f\"Time: {epoch_time:.2f}s | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STARTING FINAL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model_EfficientNet-B7-LSTM-DCT.pth\"))\n",
    "model.eval()\n",
    "\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "test_start_time = time.time()\n",
    "\n",
    "test_bar = tqdm(test_loader, desc=\"Final Testing\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for sequences, dct_features, labels in test_bar:\n",
    "        sequences = sequences.to(device, non_blocking=True)\n",
    "        dct_features = dct_features.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                preds = model(sequences, dct_features)\n",
    "        else:\n",
    "            preds = model(sequences, dct_features)\n",
    "        \n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        \n",
    "        y_true_test.extend(labels.cpu().tolist())\n",
    "        y_pred_test.extend(predicted.cpu().tolist())\n",
    "        \n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "        \n",
    "        current_test_acc = 100.0 * test_correct / test_total\n",
    "        test_bar.set_postfix({\"acc\": f\"{current_test_acc:.2f}%\"})\n",
    "\n",
    "test_time = time.time() - test_start_time\n",
    "final_test_acc = 100.0 * test_correct / test_total\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {final_test_acc:.2f}%\")\n",
    "print(f\"Test evaluation time: {test_time:.2f}s\")\n",
    "\n",
    "print(\"\\n==== DETAILED METRICS ON TEST SET ====\")\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=class_names))\n",
    "\n",
    "if \"original\" in class_names:\n",
    "    real_index = class_names.index(\"original\")\n",
    "    prec, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_test, y_pred_test, labels=[real_index], average=None\n",
    "    )\n",
    "    print(f\"\\nORIGINAL class metrics:\")\n",
    "    print(f\"Precision: {prec[0]:.4f} | Recall: {recall[0]:.4f} | \"\n",
    "          f\"F1-score: {f1[0]:.4f} | Support: {support[0]}\")\n",
    "\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Confusion Matrix - TEST SET (EfficientNet-B7 + LSTM + DCT)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"EfficientNet-B7-LSTM-DCT_confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Training Loss\", color='red')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Evolution\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\", color='blue')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Validation Accuracy Evolution\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"EfficientNet-B7-LSTM-DCT_training_evolution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = int(total_time % 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total training time: {hours:02d}h {minutes:02d}m {seconds:02d}s\")\n",
    "print(f\"Started at: {datetime.now() - timedelta(seconds=total_time)}\")\n",
    "print(f\"Finished at: {datetime.now()}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Final test accuracy: {final_test_acc:.2f}%\")\n",
    "print(f\"Model saved as: best_model_EfficientNet-B7-LSTM-DCT.pth\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\nMemory cleanup completed. Training finished successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun  7 13:53:00 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    52W / 300W |  16261MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU memory before start: 1.32 GB allocated\n",
      "GPU memory reserved: 14.93 GB reserved\n",
      "Training started at: 2025-06-07 13:53:00\n",
      "Classes detectadas: ['DeepFakeDetection', 'FaceShifter', 'FaceSwap', 'NeuraTextures', 'deepfakes', 'face2face', 'original']\n",
      "Dataset sizes - Train: 24487, Val: 3499, Test: 6999\n",
      "Using device: cuda\n",
      "GPU memory before model loading: 1.32 GB allocated\n",
      "GPU memory available: 14.58 GB\n",
      "Loading EfficientNet-B7 model...\n",
      "GPU memory after moving model to GPU: 1.55 GB allocated\n",
      "GPU memory reserved: 14.93 GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/20 | Loss Treino: 0.4468 | Val Acc: 90.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 2/20 | Loss Treino: 0.1779 | Val Acc: 91.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 3/20 | Loss Treino: 0.1287 | Val Acc: 92.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 4/20 | Loss Treino: 0.1070 | Val Acc: 90.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 5/20 | Loss Treino: 0.0870 | Val Acc: 92.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 6/20 | Loss Treino: 0.0733 | Val Acc: 92.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 7/20 | Loss Treino: 0.0626 | Val Acc: 93.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 8/20 | Loss Treino: 0.0564 | Val Acc: 93.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 9/20 | Loss Treino: 0.0473 | Val Acc: 93.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 10/20 | Loss Treino: 0.0427 | Val Acc: 92.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 11/20 | Loss Treino: 0.0395 | Val Acc: 93.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 12/20 | Loss Treino: 0.0376 | Val Acc: 93.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 13/20 | Loss Treino: 0.0293 | Val Acc: 93.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 14/20 | Loss Treino: 0.0294 | Val Acc: 93.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 15/20 | Loss Treino: 0.0271 | Val Acc: 92.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 16/20 | Loss Treino: 0.0277 | Val Acc: 92.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 17/20 | Loss Treino: 0.0250 | Val Acc: 93.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 18/20 | Loss Treino: 0.0215 | Val Acc: 91.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 19/20 | Loss Treino: 0.0223 | Val Acc: 93.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 20/20 | Loss Treino: 0.0198 | Val Acc: 94.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Métricas no conjunto TEST ====\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "DeepFakeDetection       0.99      1.00      1.00      1000\n",
      "      FaceShifter       0.96      0.96      0.96      1000\n",
      "         FaceSwap       0.96      0.96      0.96      1000\n",
      "    NeuraTextures       0.92      0.84      0.88      1000\n",
      "        deepfakes       0.95      0.97      0.96       999\n",
      "        face2face       0.96      0.95      0.95      1000\n",
      "         original       0.83      0.89      0.86      1000\n",
      "\n",
      "         accuracy                           0.94      6999\n",
      "        macro avg       0.94      0.94      0.94      6999\n",
      "     weighted avg       0.94      0.94      0.94      6999\n",
      "\n",
      "Classe ORIGINAL - Precision: 0.83, Recall: 0.89, F1-score: 0.86, Support: 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo como modelo_efficientnetb7_frames.pth\n",
      "Tempo total: 258.61 minutos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import efficientnet_b7\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) CONFIGURAÇÕES E PREPARAÇÃO\n",
    "# ---------------------------------------------------\n",
    "!nvidia-smi\n",
    "\n",
    "# Limpeza e gerenciamento de memória GPU\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.95)\n",
    "    print(f\"GPU memory before start: {torch.cuda.memory_allocated()/1024**3:.2f} GB allocated\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB reserved\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Caminhos\n",
    "base_dir = \"face_extraction/faceforensis_face_extract\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir   = os.path.join(base_dir, \"val\")\n",
    "test_dir  = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Datasets e loaders\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset   = ImageFolder(root=val_dir,   transform=transform)\n",
    "test_dataset  = ImageFolder(root=test_dir,  transform=transform)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"Classes detectadas:\", class_names)\n",
    "print(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) MODELO: EfficientNet-B7\n",
    "# ---------------------------------------------------\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU memory before model loading: {torch.cuda.memory_allocated()/1024**3:.2f} GB allocated\")\n",
    "    print(f\"GPU memory available: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated())/1024**3:.2f} GB\")\n",
    "\n",
    "print(\"Loading EfficientNet-B7 model...\")\n",
    "model = efficientnet_b7(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU memory after moving model to GPU: {torch.cuda.memory_allocated()/1024**3:.2f} GB allocated\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB reserved\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) TREINAMENTO E VALIDAÇÃO\n",
    "# ---------------------------------------------------\n",
    "\n",
    "epochs = 20\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f\"Época {epoch+1}/{epochs} - Treino\", leave=False)\n",
    "    for xb, yb in train_bar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validação\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Época {epoch+1}/{epochs} - Validação\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_bar:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            _, predicted = torch.max(preds, 1)\n",
    "            correct += (predicted == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "            acc_partial = 100.0 * (correct / total)\n",
    "            val_bar.set_postfix({\"acc\": f\"{acc_partial:.2f}%\"})\n",
    "\n",
    "    val_acc = 100.0 * correct / total\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Época {epoch+1}/{epochs} | Loss Treino: {avg_train_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) TESTE FINAL\n",
    "# ---------------------------------------------------\n",
    "\n",
    "model.eval()\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "\n",
    "test_bar = tqdm(test_loader, desc=\"Teste Final\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_bar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb)\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        y_true_test.extend(yb.cpu().tolist())\n",
    "        y_pred_test.extend(predicted.cpu().tolist())\n",
    "\n",
    "print(\"\\n==== Métricas no conjunto TEST ====\")\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=class_names))\n",
    "\n",
    "if \"original\" in class_names:\n",
    "    real_index = class_names.index(\"original\")\n",
    "    prec, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_test, y_pred_test, labels=[real_index], average=None\n",
    "    )\n",
    "    print(f\"Classe ORIGINAL - Precision: {prec[0]:.2f}, Recall: {recall[0]:.2f}, \"\n",
    "          f\"F1-score: {f1[0]:.2f}, Support: {support[0]}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=\"Blues\", ax=ax, values_format='d')\n",
    "plt.title(\"Matriz de Confusão - TESTE\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"efficientnetb7_confusao_teste.png\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5) GRÁFICOS\n",
    "# ---------------------------------------------------\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Loss Treino\")\n",
    "plt.plot(val_accuracies, label=\"Validação (%)\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.title(\"EfficientNet-B7 - Evolução Loss (Treino) e Acurácia (Val)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"efficientnetb7_evolucao.png\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6) SALVAR MODELO\n",
    "# ---------------------------------------------------\n",
    "\n",
    "torch.save(model.state_dict(), \"modelo_efficientnetb7_frames.pth\")\n",
    "print(\"Modelo salvo como modelo_efficientnetb7_frames.pth\")\n",
    "\n",
    "print(f\"Tempo total: {(time.time() - start_time)/60:.2f} minutos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting captum\n",
      "  Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 16.5 MB/s            \n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 1.8 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from captum) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.6/dist-packages (from captum) (1.10.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from captum) (3.3.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->captum) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->captum) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (8.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (0.10.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->captum) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm->captum) (3.4.0)\n",
      "Installing collected packages: importlib-resources, tqdm, captum\n",
      "Successfully installed captum-0.7.0 importlib-resources-5.4.0 tqdm-4.64.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 16 10:48:56 2025       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   28C    P0    35W / 300W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA Tesla P1...  Off  | 00000000:07:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    34W / 300W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando análise de explicabilidade...\n",
      "Salvando resultados em: explainability_results\n",
      "--------------------------------------------------\n",
      "Processando: Classe real [DeepFakeDetection] → Predito [DeepFakeDetection] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/DeepFakeDetection/saliency/img_01_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/DeepFakeDetection/integrated_gradients/img_01_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/DeepFakeDetection/input_x_gradient/img_01_combined.png\n",
      "  ✓ Concluído para DeepFakeDetection - Imagem 1\n",
      "\n",
      "Processando: Classe real [DeepFakeDetection] → Predito [DeepFakeDetection] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/DeepFakeDetection/saliency/img_02_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/DeepFakeDetection/integrated_gradients/img_02_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/DeepFakeDetection/input_x_gradient/img_02_combined.png\n",
      "  ✓ Concluído para DeepFakeDetection - Imagem 2\n",
      "\n",
      "Processando: Classe real [DeepFakeDetection] → Predito [DeepFakeDetection] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/DeepFakeDetection/saliency/img_03_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/DeepFakeDetection/integrated_gradients/img_03_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/DeepFakeDetection/input_x_gradient/img_03_combined.png\n",
      "  ✓ Concluído para DeepFakeDetection - Imagem 3\n",
      "\n",
      "Processando: Classe real [deepfakes] → Predito [deepfakes] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/deepfakes/saliency/img_01_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/deepfakes/integrated_gradients/img_01_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/deepfakes/input_x_gradient/img_01_combined.png\n",
      "  ✓ Concluído para deepfakes - Imagem 1\n",
      "\n",
      "Processando: Classe real [deepfakes] → Predito [deepfakes] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/deepfakes/saliency/img_02_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/deepfakes/integrated_gradients/img_02_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/deepfakes/input_x_gradient/img_02_combined.png\n",
      "  ✓ Concluído para deepfakes - Imagem 2\n",
      "\n",
      "Processando: Classe real [deepfakes] → Predito [deepfakes] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/deepfakes/saliency/img_03_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/deepfakes/integrated_gradients/img_03_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/deepfakes/input_x_gradient/img_03_combined.png\n",
      "  ✓ Concluído para deepfakes - Imagem 3\n",
      "\n",
      "Processando: Classe real [face2face] → Predito [face2face] (Confiança: 0.990)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/face2face/saliency/img_01_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/face2face/integrated_gradients/img_01_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/face2face/input_x_gradient/img_01_combined.png\n",
      "  ✓ Concluído para face2face - Imagem 1\n",
      "\n",
      "Processando: Classe real [face2face] → Predito [face2face] (Confiança: 0.983)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/face2face/saliency/img_02_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/face2face/integrated_gradients/img_02_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/face2face/input_x_gradient/img_02_combined.png\n",
      "  ✓ Concluído para face2face - Imagem 2\n",
      "\n",
      "Processando: Classe real [face2face] → Predito [face2face] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/face2face/saliency/img_03_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/face2face/integrated_gradients/img_03_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/face2face/input_x_gradient/img_03_combined.png\n",
      "  ✓ Concluído para face2face - Imagem 3\n",
      "\n",
      "Processando: Classe real [FaceShifter] → Predito [FaceShifter] (Confiança: 0.996)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/FaceShifter/saliency/img_01_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/FaceShifter/integrated_gradients/img_01_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/FaceShifter/input_x_gradient/img_01_combined.png\n",
      "  ✓ Concluído para FaceShifter - Imagem 1\n",
      "\n",
      "Processando: Classe real [FaceShifter] → Predito [FaceShifter] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/FaceShifter/saliency/img_02_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/FaceShifter/integrated_gradients/img_02_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/FaceShifter/input_x_gradient/img_02_combined.png\n",
      "  ✓ Concluído para FaceShifter - Imagem 2\n",
      "\n",
      "Processando: Classe real [FaceShifter] → Predito [FaceShifter] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/FaceShifter/saliency/img_03_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/FaceShifter/integrated_gradients/img_03_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/FaceShifter/input_x_gradient/img_03_combined.png\n",
      "  ✓ Concluído para FaceShifter - Imagem 3\n",
      "\n",
      "Processando: Classe real [FaceSwap] → Predito [FaceSwap] (Confiança: 0.998)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/FaceSwap/saliency/img_01_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/FaceSwap/integrated_gradients/img_01_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/FaceSwap/input_x_gradient/img_01_combined.png\n",
      "  ✓ Concluído para FaceSwap - Imagem 1\n",
      "\n",
      "Processando: Classe real [FaceSwap] → Predito [FaceSwap] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/FaceSwap/saliency/img_02_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/FaceSwap/integrated_gradients/img_02_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/FaceSwap/input_x_gradient/img_02_combined.png\n",
      "  ✓ Concluído para FaceSwap - Imagem 2\n",
      "\n",
      "Processando: Classe real [FaceSwap] → Predito [FaceSwap] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/FaceSwap/saliency/img_03_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/FaceSwap/integrated_gradients/img_03_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/FaceSwap/input_x_gradient/img_03_combined.png\n",
      "  ✓ Concluído para FaceSwap - Imagem 3\n",
      "\n",
      "Processando: Classe real [NeuralTextures] → Predito [NeuralTextures] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/NeuralTextures/saliency/img_01_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/NeuralTextures/integrated_gradients/img_01_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/NeuralTextures/input_x_gradient/img_01_combined.png\n",
      "  ✓ Concluído para NeuralTextures - Imagem 1\n",
      "\n",
      "Processando: Classe real [NeuralTextures] → Predito [NeuralTextures] (Confiança: 1.000)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/NeuralTextures/saliency/img_02_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/NeuralTextures/integrated_gradients/img_02_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/NeuralTextures/input_x_gradient/img_02_combined.png\n",
      "  ✓ Concluído para NeuralTextures - Imagem 2\n",
      "\n",
      "Processando: Classe real [NeuralTextures] → Predito [original] (Confiança: 0.937)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/NeuralTextures/saliency/img_03_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/NeuralTextures/integrated_gradients/img_03_combined.png\n",
      "  Calculando Input × Gradient...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: explainability_results/NeuralTextures/input_x_gradient/img_03_combined.png\n",
      "  ✓ Concluído para NeuralTextures - Imagem 3\n",
      "\n",
      "Processando: Classe real [original] → Predito [original] (Confiança: 0.972)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/original/saliency/img_01_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/original/integrated_gradients/img_01_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/original/input_x_gradient/img_01_combined.png\n",
      "  ✓ Concluído para original - Imagem 1\n",
      "\n",
      "Processando: Classe real [original] → Predito [original] (Confiança: 0.952)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/original/saliency/img_02_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/original/integrated_gradients/img_02_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/original/input_x_gradient/img_02_combined.png\n",
      "  ✓ Concluído para original - Imagem 2\n",
      "\n",
      "Processando: Classe real [original] → Predito [original] (Confiança: 0.951)\n",
      "  Calculando Saliency...\n",
      "Saved: explainability_results/original/saliency/img_03_combined.png\n",
      "  Calculando Integrated Gradients...\n",
      "Saved: explainability_results/original/integrated_gradients/img_03_combined.png\n",
      "  Calculando Input × Gradient...\n",
      "Saved: explainability_results/original/input_x_gradient/img_03_combined.png\n",
      "  ✓ Concluído para original - Imagem 3\n",
      "\n",
      "--------------------------------------------------\n",
      "Análise concluída!\n",
      "Total de imagens processadas: 21\n",
      "Estrutura de pastas criada em: explainability_results\n",
      "\n",
      "Estrutura de pastas:\n",
      "├── DeepFakeDetection/\n",
      "│   ├── saliency/\n",
      "│   ├── integrated_gradients/\n",
      "│   ├── input_x_gradient/\n",
      "│   └── original_images/\n",
      "├── deepfakes/\n",
      "│   ├── saliency/\n",
      "│   ├── integrated_gradients/\n",
      "│   ├── input_x_gradient/\n",
      "│   └── original_images/\n",
      "├── face2face/\n",
      "│   ├── saliency/\n",
      "│   ├── integrated_gradients/\n",
      "│   ├── input_x_gradient/\n",
      "│   └── original_images/\n",
      "├── FaceShifter/\n",
      "│   ├── saliency/\n",
      "│   ├── integrated_gradients/\n",
      "│   ├── input_x_gradient/\n",
      "│   └── original_images/\n",
      "├── FaceSwap/\n",
      "│   ├── saliency/\n",
      "│   ├── integrated_gradients/\n",
      "│   ├── input_x_gradient/\n",
      "│   └── original_images/\n",
      "├── NeuralTextures/\n",
      "│   ├── saliency/\n",
      "│   ├── integrated_gradients/\n",
      "│   ├── input_x_gradient/\n",
      "│   └── original_images/\n",
      "├── original/\n",
      "│   ├── saliency/\n",
      "│   ├── integrated_gradients/\n",
      "│   ├── input_x_gradient/\n",
      "│   └── original_images/\n",
      "\n",
      "Summary salvo em: explainability_results/analysis_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from captum.attr import Saliency, IntegratedGradients, InputXGradient\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"face_extraction/faceforensis_face_extract\"\n",
    "DATASET_ROOT = os.path.join(base_dir, \"val\")\n",
    "MODEL_PATH = \"./modelo_efficientnetb7_frames.pth\"\n",
    "\n",
    "# Create output directory structure\n",
    "OUTPUT_DIR = \"explainability_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Carrega modelo EfficientNet-B7\n",
    "model = models.efficientnet_b7(pretrained=False)\n",
    "num_features = model.classifier[1].in_features  # A camada Linear está no índice 1\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.5, inplace=True),\n",
    "    torch.nn.Linear(num_features, 7)\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Transforms para EfficientNet-B7 (resolução 600x600 é ideal, mas 224x224 também funciona)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ou (600, 600) para melhor performance\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(DATASET_ROOT, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Nomes das classes\n",
    "class_names = [\n",
    "    \"DeepFakeDetection\", \"deepfakes\", \"face2face\",\n",
    "    \"FaceShifter\", \"FaceSwap\", \"NeuralTextures\", \"original\"\n",
    "]\n",
    "\n",
    "# Create folders for each class\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(OUTPUT_DIR, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    # Create subfolders for each method\n",
    "    os.makedirs(os.path.join(class_dir, \"saliency\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(class_dir, \"integrated_gradients\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(class_dir, \"input_x_gradient\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(class_dir, \"original_images\"), exist_ok=True)\n",
    "\n",
    "# Inicializa métodos\n",
    "saliency = Saliency(model)\n",
    "ig = IntegratedGradients(model)\n",
    "ixg = InputXGradient(model)\n",
    "\n",
    "# Visualização e salvamento\n",
    "def save_visualization(img_tensor, attr_map, title, save_path, class_name, img_idx, method_name):\n",
    "    img = img_tensor.squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
    "    attr = attr_map.squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
    "    \n",
    "    # Normalização dos mapas de atribuição\n",
    "    attr = (attr - attr.min()) / (attr.max() - attr.min() + 1e-8)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "    \n",
    "    # Create the combined visualization\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"Original Image\", fontsize=14)\n",
    "    axs[0].axis(\"off\")\n",
    "    \n",
    "    axs[1].imshow(attr, cmap=\"hot\")\n",
    "    axs[1].set_title(title, fontsize=14)\n",
    "    axs[1].axis(\"off\")\n",
    "    \n",
    "    plt.suptitle(f\"Class: {class_name} - Image {img_idx}\", fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save combined visualization\n",
    "    combined_path = os.path.join(save_path, class_name, method_name, f\"img_{img_idx:02d}_combined.png\")\n",
    "    plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save individual images\n",
    "    # Original image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Original - {class_name} - Image {img_idx}\", fontsize=14)\n",
    "    plt.axis(\"off\")\n",
    "    orig_path = os.path.join(save_path, class_name, \"original_images\", f\"img_{img_idx:02d}_original.png\")\n",
    "    plt.savefig(orig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Attribution map\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(attr, cmap=\"hot\")\n",
    "    plt.title(f\"{title} - {class_name} - Image {img_idx}\", fontsize=14)\n",
    "    plt.axis(\"off\")\n",
    "    attr_path = os.path.join(save_path, class_name, method_name, f\"img_{img_idx:02d}_attribution.png\")\n",
    "    plt.savefig(attr_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved: {combined_path}\")\n",
    "\n",
    "# Separar 3 imagens por classe\n",
    "seen_per_class = {cls: 0 for cls in range(len(class_names))}\n",
    "max_per_class = 3\n",
    "count = 0\n",
    "\n",
    "print(\"Iniciando análise de explicabilidade...\")\n",
    "print(f\"Salvando resultados em: {OUTPUT_DIR}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for batch_idx, (xb, yb) in enumerate(loader):\n",
    "    label = yb.item()\n",
    "    if seen_per_class[label] < max_per_class:\n",
    "        img_idx = seen_per_class[label] + 1\n",
    "        class_name = class_names[label]\n",
    "        \n",
    "        xb = xb.to(device)\n",
    "        xb.requires_grad = True\n",
    "        \n",
    "        preds = model(xb)\n",
    "        pred_label = preds.argmax(dim=1)\n",
    "        conf = torch.softmax(preds, dim=1)[0, pred_label].item()\n",
    "        \n",
    "        print(f\"Processando: Classe real [{class_name}] → Predito [{class_names[pred_label]}] (Confiança: {conf:.3f})\")\n",
    "        \n",
    "        # Aplicar métodos de explicabilidade\n",
    "        print(\"  Calculando Saliency...\")\n",
    "        sal = saliency.attribute(xb, target=pred_label)\n",
    "        save_visualization(xb, sal, \"Saliency Map\", OUTPUT_DIR, class_name, img_idx, \"saliency\")\n",
    "        \n",
    "        print(\"  Calculando Integrated Gradients...\")\n",
    "        ig_attr = ig.attribute(xb, target=pred_label, baselines=xb * 0)\n",
    "        save_visualization(xb, ig_attr, \"Integrated Gradients\", OUTPUT_DIR, class_name, img_idx, \"integrated_gradients\")\n",
    "        \n",
    "        print(\"  Calculando Input × Gradient...\")\n",
    "        ixg_attr = ixg.attribute(xb, target=pred_label)\n",
    "        save_visualization(xb, ixg_attr, \"Input × Gradient\", OUTPUT_DIR, class_name, img_idx, \"input_x_gradient\")\n",
    "        \n",
    "        seen_per_class[label] += 1\n",
    "        count += 1\n",
    "        print(f\"  ✓ Concluído para {class_name} - Imagem {img_idx}\")\n",
    "        print()\n",
    "    \n",
    "    # Parar quando todas as classes tiverem 3 exemplos\n",
    "    if all(v == max_per_class for v in seen_per_class.values()):\n",
    "        break\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Análise concluída!\")\n",
    "print(f\"Total de imagens processadas: {count}\")\n",
    "print(f\"Estrutura de pastas criada em: {OUTPUT_DIR}\")\n",
    "print(\"\\nEstrutura de pastas:\")\n",
    "for class_name in class_names:\n",
    "    print(f\"├── {class_name}/\")\n",
    "    print(f\"│   ├── saliency/\")\n",
    "    print(f\"│   ├── integrated_gradients/\")\n",
    "    print(f\"│   ├── input_x_gradient/\")\n",
    "    print(f\"│   └── original_images/\")\n",
    "print()\n",
    "\n",
    "# Criar um summary dos resultados\n",
    "summary_file = os.path.join(OUTPUT_DIR, \"analysis_summary.txt\")\n",
    "with open(summary_file, \"w\") as f:\n",
    "    f.write(\"Explainability Analysis Summary\\n\")\n",
    "    f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "    f.write(f\"Total images processed: {count}\\n\")\n",
    "    f.write(f\"Images per class: {max_per_class}\\n\")\n",
    "    f.write(f\"Classes analyzed: {len(class_names)}\\n\\n\")\n",
    "    f.write(\"Class distribution:\\n\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        f.write(f\"  {class_name}: {seen_per_class[i]} images\\n\")\n",
    "    f.write(\"\\nMethods applied:\\n\")\n",
    "    f.write(\"  - Saliency Maps\\n\")\n",
    "    f.write(\"  - Integrated Gradients\\n\")\n",
    "    f.write(\"  - Input × Gradient\\n\")\n",
    "\n",
    "print(f\"Summary salvo em: {summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 16 10:58:30 2025       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P0    35W / 300W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA Tesla P1...  Off  | 00000000:07:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P0    52W / 300W |  16251MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root         1  0.5  0.0 363848 79196 pts/0    Ssl+ 10:46   0:03 /usr/bin/python3 /usr/local/bin/jupyter-notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --allow-root\n",
      "root     20706 11.5  0.0 548428 50656 ?        Ssl  10:58   0:00 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-158d39ed-d8c1-4bd2-9630-25b847df71f2.json\n",
      "root     20720  0.0  0.0   4644   864 pts/1    Ss+  10:58   0:00 /bin/sh -c ps aux | grep python\n",
      "root     20722  0.0  0.0  13220  1088 pts/1    S+   10:58   0:00 grep python\n",
      "root         1  0.5  0.0 363848 79196 pts/0    Ssl+ 10:46   0:03 /usr/bin/python3 /usr/local/bin/jupyter-notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --allow-root\n",
      "root     20706 11.5  0.0 548428 51508 ?        Ssl  10:58   0:00 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-158d39ed-d8c1-4bd2-9630-25b847df71f2.json\n",
      "root     20723  0.0  0.0   4644   828 pts/1    Ss+  10:58   0:00 /bin/sh -c ps aux | grep jupyter\n",
      "root     20725  0.0  0.0  13220  1116 pts/1    S+   10:58   0:00 grep jupyter\n"
     ]
    }
   ],
   "source": [
    "!ps aux | grep python\n",
    "!ps aux | grep jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reiniciar PyTorch CUDA\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/explainability_results.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Will produce 'explainability_results.zip' from the folder\n",
    "shutil.make_archive(\"explainability_results\", \"zip\", \"explainability_results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from ./modelo_efficientnetb7_frames.pth\n",
      "Using target layer: ConvNormActivation(\n",
      "  (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(2560, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (2): SiLU(inplace=True)\n",
      ")\n",
      "Starting processing with 3499 images...\n",
      "Processing up to 3 images per class\n",
      "Processing image 0: True=DeepFakeDetection, Pred=DeepFakeDetection, Conf=0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: explainability_results/gradcam_0_DeepFakeDetection.jpg\n",
      "Processing image 1: True=DeepFakeDetection, Pred=DeepFakeDetection, Conf=0.655\n",
      "Saved: explainability_results/gradcam_1_DeepFakeDetection.jpg\n",
      "Processing image 2: True=DeepFakeDetection, Pred=DeepFakeDetection, Conf=0.655\n",
      "Saved: explainability_results/gradcam_2_DeepFakeDetection.jpg\n",
      "Processing image 500: True=deepfakes, Pred=deepfakes, Conf=0.974\n",
      "Saved: explainability_results/gradcam_500_deepfakes.jpg\n",
      "Processing image 501: True=deepfakes, Pred=deepfakes, Conf=0.995\n",
      "Saved: explainability_results/gradcam_501_deepfakes.jpg\n",
      "Processing image 502: True=deepfakes, Pred=deepfakes, Conf=0.767\n",
      "Saved: explainability_results/gradcam_502_deepfakes.jpg\n",
      "Processing image 1000: True=face2face, Pred=deepfakes, Conf=0.465\n",
      "Saved: explainability_results/gradcam_1000_face2face.jpg\n",
      "Processing image 1001: True=face2face, Pred=deepfakes, Conf=0.435\n",
      "Saved: explainability_results/gradcam_1001_face2face.jpg\n",
      "Processing image 1002: True=face2face, Pred=deepfakes, Conf=0.354\n",
      "Saved: explainability_results/gradcam_1002_face2face.jpg\n",
      "Processing image 1499: True=FaceShifter, Pred=FaceShifter, Conf=0.334\n",
      "Saved: explainability_results/gradcam_1499_FaceShifter.jpg\n",
      "Processing image 1500: True=FaceShifter, Pred=FaceSwap, Conf=0.755\n",
      "Saved: explainability_results/gradcam_1500_FaceShifter.jpg\n",
      "Processing image 1501: True=FaceShifter, Pred=deepfakes, Conf=0.420\n",
      "Saved: explainability_results/gradcam_1501_FaceShifter.jpg\n",
      "Processing image 1999: True=FaceSwap, Pred=FaceShifter, Conf=0.641\n",
      "Saved: explainability_results/gradcam_1999_FaceSwap.jpg\n",
      "Processing image 2000: True=FaceSwap, Pred=FaceShifter, Conf=0.711\n",
      "Saved: explainability_results/gradcam_2000_FaceSwap.jpg\n",
      "Processing image 2001: True=FaceSwap, Pred=FaceShifter, Conf=0.521\n",
      "Saved: explainability_results/gradcam_2001_FaceSwap.jpg\n",
      "Processing image 2499: True=NeuralTextures, Pred=FaceSwap, Conf=0.861\n",
      "Saved: explainability_results/gradcam_2499_NeuralTextures.jpg\n",
      "Processing image 2500: True=NeuralTextures, Pred=FaceSwap, Conf=0.400\n",
      "Saved: explainability_results/gradcam_2500_NeuralTextures.jpg\n",
      "Processing image 2501: True=NeuralTextures, Pred=deepfakes, Conf=0.874\n",
      "Saved: explainability_results/gradcam_2501_NeuralTextures.jpg\n",
      "Processing image 2999: True=original, Pred=FaceShifter, Conf=0.773\n",
      "Saved: explainability_results/gradcam_2999_original.jpg\n",
      "Processing image 3000: True=original, Pred=FaceShifter, Conf=0.703\n",
      "Saved: explainability_results/gradcam_3000_original.jpg\n",
      "Processing image 3001: True=original, Pred=FaceSwap, Conf=0.597\n",
      "Saved: explainability_results/gradcam_3001_original.jpg\n",
      "Completed processing maximum images for all classes\n",
      "Processing completed!\n",
      "Results saved in: explainability_results\n",
      "Images processed per class: {0: 3, 1: 3, 2: 3, 3: 3, 4: 3, 5: 3, 6: 3}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Configurações\n",
    "base_dir = \"face_extraction/faceforensis_face_extract\"\n",
    "DATASET_ROOT = os.path.join(base_dir, \"val\")\n",
    "MODEL_PATH = \"./modelo_efficientnetb7_frames.pth\"\n",
    "\n",
    "# Create output directory structure\n",
    "OUTPUT_DIR = \"explainability_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carregar modelo EfficientNetB7\n",
    "model = models.efficientnet_b7(pretrained=False)\n",
    "# EfficientNetB7 uses 'classifier' instead of 'fc'\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.5, inplace=True),\n",
    "    torch.nn.Linear(model.classifier[1].in_features, 7)\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "try:\n",
    "    state_dict = torch.load(MODEL_PATH, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f\"Model loaded successfully from {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Make sure the model file exists and was trained with EfficientNetB7\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Classes\n",
    "class_names = [\n",
    "    \"DeepFakeDetection\", \"deepfakes\", \"face2face\",\n",
    "    \"FaceShifter\", \"FaceSwap\", \"NeuralTextures\", \"original\"\n",
    "]\n",
    "\n",
    "# Transformação para EfficientNetB7 (entrada 600x600)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((600, 600)),  # EfficientNetB7 uses 600x600\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset e loader\n",
    "dataset = ImageFolder(DATASET_ROOT, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# GradCAM (fixed __init__ method)\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].detach()\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = torch.argmax(output, dim=1).item()\n",
    "        loss = output[0, class_idx]\n",
    "        loss.backward()\n",
    "\n",
    "        # Handle case where gradients might be None\n",
    "        if self.gradients is None or self.activations is None:\n",
    "            print(\"Warning: Gradients or activations are None\")\n",
    "            return np.zeros((input_tensor.shape[-2], input_tensor.shape[-1]))\n",
    "\n",
    "        weights = torch.mean(self.gradients, dim=[2, 3], keepdim=True)\n",
    "        cam = torch.sum(weights * self.activations, dim=1).squeeze()\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        # Normalize CAM\n",
    "        if cam.max() > 0:\n",
    "            cam -= cam.min()\n",
    "            cam /= cam.max()\n",
    "        \n",
    "        cam = cam.cpu().numpy()\n",
    "        return cam\n",
    "\n",
    "# Get the appropriate layer for EfficientNetB7\n",
    "# EfficientNetB7 structure: features -> avgpool -> classifier\n",
    "# We'll use the last convolutional block in features\n",
    "def get_target_layer(model):\n",
    "    # Navigate through EfficientNetB7 features to get the last conv layer\n",
    "    features = model.features\n",
    "    # The last block in EfficientNetB7 features\n",
    "    return features[-1]\n",
    "\n",
    "target_layer = get_target_layer(model)\n",
    "print(f\"Using target layer: {target_layer}\")\n",
    "\n",
    "# Instanciar GradCAM\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "# Função para converter imagem tensor -> RGB normalizado\n",
    "def tensor_to_image(tensor):\n",
    "    image = tensor.squeeze().detach().cpu().numpy()\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    # Denormalize using ImageNet stats\n",
    "    image = image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
    "    return np.clip(image, 0, 1)\n",
    "\n",
    "# Controle por classe\n",
    "seen_per_class = {cls: 0 for cls in range(len(class_names))}\n",
    "max_per_class = 3\n",
    "\n",
    "print(f\"Starting processing with {len(dataset)} images...\")\n",
    "print(f\"Processing up to {max_per_class} images per class\")\n",
    "\n",
    "# Processar imagens\n",
    "for idx, (xb, yb) in enumerate(loader):\n",
    "    label = yb.item()\n",
    "    if seen_per_class[label] >= max_per_class:\n",
    "        continue\n",
    "\n",
    "    xb = xb.to(device)\n",
    "    xb.requires_grad = True\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(xb)\n",
    "    \n",
    "    pred_label = preds.argmax(dim=1).item()\n",
    "    conf = torch.softmax(preds, dim=1)[0, pred_label].item()\n",
    "\n",
    "    print(f\"Processing image {idx}: True={class_names[label]}, Pred={class_names[pred_label]}, Conf={conf:.3f}\")\n",
    "\n",
    "    # Gerar heatmap Grad-CAM\n",
    "    try:\n",
    "        xb.requires_grad = True  # Reset grad requirement\n",
    "        cam = gradcam.generate(xb, class_idx=pred_label)\n",
    "        image = tensor_to_image(xb)\n",
    "\n",
    "        # Redimensionar heatmap para o tamanho da imagem (600x600)\n",
    "        cam_resized = np.uint8(255 * cam)\n",
    "        cam_resized = Image.fromarray(cam_resized).resize((600, 600), resample=Image.BILINEAR)\n",
    "        cam_resized = np.array(cam_resized)\n",
    "        cam_colored = plt.cm.jet(cam_resized / 255.0)[:, :, :3]\n",
    "\n",
    "        # Overlay\n",
    "        overlay = 0.6 * cam_colored + 0.4 * image\n",
    "\n",
    "        # Título com info\n",
    "        title = f\"True: {class_names[label]} → Pred: {class_names[pred_label]} (Conf: {conf:.3f})\"\n",
    "\n",
    "        # Plotar e salvar\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Create subplots for better visualization\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cam_resized, cmap='jet')\n",
    "        plt.title(\"GradCAM Heatmap\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(overlay)\n",
    "        plt.title(\"Overlay\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(title, fontsize=12)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Fixed variable name: SAVE_DIR -> OUTPUT_DIR\n",
    "        save_path = os.path.join(OUTPUT_DIR, f\"gradcam_{idx}_{class_names[label]}.jpg\")\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        seen_per_class[label] += 1\n",
    "        print(f\"Saved: {save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if we've processed enough images for all classes\n",
    "    if all(v >= max_per_class for v in seen_per_class.values()):\n",
    "        print(\"Completed processing maximum images for all classes\")\n",
    "        break\n",
    "\n",
    "print(\"Processing completed!\")\n",
    "print(\"Results saved in:\", OUTPUT_DIR)\n",
    "print(\"Images processed per class:\", seen_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
